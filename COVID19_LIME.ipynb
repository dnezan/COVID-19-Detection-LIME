{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID19_LIME",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UYyw4VBQzrc",
        "colab_type": "text"
      },
      "source": [
        "# Explainable COVID-19 Pneumonia\n",
        "### CS-GY-6133 Spring 2020\n",
        "### Project 5\n",
        "### Dinesh Sreekanthan(NetID:ds5786)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uos9-CLoRBRM",
        "colab_type": "code",
        "outputId": "0457ab8f-7e07-42a4-e1b8-d29ff6f6a619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdD8O24uRCPN",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "After you succsesfully run this notebook, you will have a cloned file in your Google Colab Drive with file name __COVID(ds5786)__. <br> This is a replication of a study on COVID 19.\n",
        "\n",
        "Let's start!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4iGZ-jSRJ2c",
        "colab_type": "text"
      },
      "source": [
        "# Mount to your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9OFpQO8RPgs",
        "colab_type": "code",
        "outputId": "af3bb910-3298-47d8-ecb3-8e8900cdb744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXyYafdvRZbs",
        "colab_type": "text"
      },
      "source": [
        "# Create a file to your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22Tz2wlARjyB",
        "colab_type": "code",
        "outputId": "4b171ef1-bc15-4523-a81c-d1f47007fbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVSRY6ftRm7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ea16017b-a3e5-4a66-994f-49b31c467c93"
      },
      "source": [
        "!mkdir \"COVID(ds5786)\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘COVID(ds5786)’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btngttm4RqLr",
        "colab_type": "text"
      },
      "source": [
        "by running this cell, you will have a directory called __\"COVID(ds5786)\"__ in your google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k68czZMlRu90",
        "colab_type": "code",
        "outputId": "5033d061-d883-46d3-a058-52256e85c090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " BUGS.gdoc\t\t\t\t    Homework\n",
            " BUGS.txt\t\t\t\t   'Homework1 Fall 2018.pdf'\n",
            "'challenges_Bigdata (1).gdoc'\t\t    hw3_p4.sql\n",
            "'challenges_Bigdata (2).gdoc'\t\t    Notes\n",
            " challenges_Bigdata.docx\t\t    os\n",
            " challenges_Bigdata.gdoc\t\t    project\n",
            "'Colab Notebooks'\t\t\t   'Project Report 1.docx'\n",
            "'COVID(ds5786)'\t\t\t\t   'Project Report 1.gdoc'\n",
            "'CS6133_MINST(id1,id2)'\t\t\t    ScannedDocument.pdf\n",
            "'CS 6643 Project 2: Human Detection.gdoc'   Scans\n",
            "'DBMS Project'\t\t\t\t   'seat map.pdf'\n",
            "'Dinesh _ NYU RESUME.gdoc'\t\t   'Untitled document.gdoc'\n",
            "'Dinesh _ NYU RESUME.pdf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDPDqAqiRysT",
        "colab_type": "text"
      },
      "source": [
        "# Clone Github repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgNquH-rSDFp",
        "colab_type": "text"
      },
      "source": [
        "First, you need to move your current location to the COVID(ds5786), and clone the github repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyJuw1YaSHAx",
        "colab_type": "code",
        "outputId": "3d4fa8db-b626-4052-abce-e382aa8c186f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/COVID(ds5786)/\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/COVID(ds5786)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhx1n-UeSKYU",
        "colab_type": "code",
        "outputId": "bf188520-fb63-416e-ada0-bfa1d4c93355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!git clone https://github.com/dnezan/Explainable-COVID-19-Pneumonia.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Explainable-COVID-19-Pneumonia' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAi11OCZSPfK",
        "colab_type": "code",
        "outputId": "67188277-5113-4248-cfcf-6f3dc0831f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oWbzyRnSS9z",
        "colab_type": "code",
        "outputId": "2e152390-672f-4f9d-f22c-2f5221f107d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "azure  config.yml  data  documents  LICENSE  requirements.txt  results\tsrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTuxY28UCPgD",
        "colab_type": "text"
      },
      "source": [
        "Install the necessary requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ayaYtma9vOi",
        "colab_type": "code",
        "outputId": "df1fcac4-3a14-4f47-d6aa-cee7f0acdaba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyyaml==5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/c9/e5be955a117a1ac548cdd31e37e8fd7b02ce987f9655f5c7563c656d5dcb/PyYAML-5.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 2.8MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/4f/dd381ecf6c6ab9bcdaa8ea912e866dedc6e696756156d8ecc087e20817e2/matplotlib-3.1.1-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 280kB/s \n",
            "\u001b[?25hCollecting tqdm==4.40.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/32/5144caf0478b1f26bd9d97f510a47336cf4ac0f96c6bc3b5af20d4173920/tqdm-4.40.2-py2.py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[?25hCollecting opencv_python==4.1.0.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 1.6MB/s \n",
            "\u001b[?25hCollecting tensorflow_gpu==2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/ce/701867b176b085574e63682a2774bf4851e2ce95343be7d8f1d8fbf0331b/tensorflow_gpu-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 40kB/s \n",
            "\u001b[?25hCollecting dill==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/7a/70803635c850e351257029089d38748516a280864c97cbc73087afef6d51/dill-0.3.0.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 53.1MB/s \n",
            "\u001b[?25hCollecting scikit_image==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\n",
            "\u001b[K     |████████████████████████████████| 26.3MB 65.5MB/s \n",
            "\u001b[?25hCollecting numpy==1.17.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 1.2MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 36.6MB/s \n",
            "\u001b[?25hCollecting pydicom==1.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/e6/4cae2b4b2fdbea5e2ddd188361139606d8f10f710ba1abecd6600da099c3/pydicom-1.4.2-py2.py3-none-any.whl (35.3MB)\n",
            "\u001b[K     |████████████████████████████████| 35.3MB 131kB/s \n",
            "\u001b[?25hCollecting imbalanced_learn==0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/aa/eba717a14df36f0b6f000ebfaf24c3189cd7987130f66cc3513efead8c2a/imbalanced_learn-0.6.1-py3-none-any.whl (162kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 51.3MB/s \n",
            "\u001b[?25hCollecting tensorboard==2.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 37.2MB/s \n",
            "\u001b[?25hCollecting lime==0.1.1.37\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/e0/60070b461a589b2fee0dbc45df9987f150fca83667c2f8a064cef7dbac6b/lime-0.1.1.37.tar.gz (275kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->-r requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->-r requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (1.28.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit_image==0.15.0->-r requirements.txt (line 7)) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit_image==0.15.0->-r requirements.txt (line 7)) (2.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit_image==0.15.0->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit_image==0.15.0->-r requirements.txt (line 7)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit_image==0.15.0->-r requirements.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->-r requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced_learn==0.6.1->-r requirements.txt (line 11)) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced_learn==0.6.1->-r requirements.txt (line 11)) (0.14.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.0.2->-r requirements.txt (line 12)) (46.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.0.2->-r requirements.txt (line 12)) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.0.2->-r requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.0.2->-r requirements.txt (line 12)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.0.2->-r requirements.txt (line 12)) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.0.2->-r requirements.txt (line 12)) (3.2.1)\n",
            "Collecting progressbar\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==2.0.1->-r requirements.txt (line 5)) (2.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit_image==0.15.0->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.0.2->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.0.2->-r requirements.txt (line 12)) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.0.2->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.0.2->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.0.2->-r requirements.txt (line 12)) (2.9)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.0.2->-r requirements.txt (line 12)) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.0.2->-r requirements.txt (line 12)) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.0.2->-r requirements.txt (line 12)) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.0.2->-r requirements.txt (line 12)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard==2.0.2->-r requirements.txt (line 12)) (0.4.8)\n",
            "Building wheels for collected packages: pyyaml, dill, lime, gast, progressbar\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.2-cp36-cp36m-linux_x86_64.whl size=44209 sha256=e23cda9cf824189a13fefbde7b9b24a5670c2934c4025b223df79542dfbbe17d\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/b7/c7/2ada654ee54483c9329871665aaf4a6056c3ce36f29cf66e67\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.0-cp36-none-any.whl size=77512 sha256=3c5a28f6fcc2ce2a4f5befe0457d2a5798a7dd6117fd107f51e69afd0723188c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/de/a4/a91eec4eea652104d8c81b633f32ead5eb57d1b294eab24167\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.1.1.37-cp36-none-any.whl size=284277 sha256=e1b8974fa3e8028474743426096cbedc64f2f7368ca191d9c08c61757471d504\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/38/e7/50d75d4fb75afa604570dc42f20c5c5f5ab26d3fbe8d6ef27b\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=84cafea8f526670424cb3f05140b65e93860606368b510d61cb5cae0dfb2dbc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12074 sha256=66888ad1d4e044ea70b11d2b2405841e13d56aecce0f3a87c94e96c2f1f9c6d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
            "Successfully built pyyaml dill lime gast progressbar\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.9 has requirement dill>=0.3.1, but you'll have dill 0.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyyaml, numpy, matplotlib, tqdm, opencv-python, tensorboard, gast, tensorflow-estimator, tensorflow-gpu, dill, scikit-image, pandas, pydicom, imbalanced-learn, progressbar, lime\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: numpy 1.18.3\n",
            "    Uninstalling numpy-1.18.3:\n",
            "      Successfully uninstalled numpy-1.18.3\n",
            "  Found existing installation: matplotlib 3.2.1\n",
            "    Uninstalling matplotlib-3.2.1:\n",
            "      Successfully uninstalled matplotlib-3.2.1\n",
            "  Found existing installation: tqdm 4.38.0\n",
            "    Uninstalling tqdm-4.38.0:\n",
            "      Successfully uninstalled tqdm-4.38.0\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: dill 0.3.1.1\n",
            "    Uninstalling dill-0.3.1.1:\n",
            "      Successfully uninstalled dill-0.3.1.1\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: pandas 1.0.3\n",
            "    Uninstalling pandas-1.0.3:\n",
            "      Successfully uninstalled pandas-1.0.3\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed dill-0.3.0 gast-0.2.2 imbalanced-learn-0.6.1 lime-0.1.1.37 matplotlib-3.1.1 numpy-1.17.4 opencv-python-4.1.0.25 pandas-0.25.3 progressbar-2.5 pydicom-1.4.2 pyyaml-5.2 scikit-image-0.15.0 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.1 tqdm-4.40.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViYClGWu4NaV",
        "colab_type": "text"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmIrWBUAMVpK",
        "colab_type": "text"
      },
      "source": [
        "Save the datasets in your Google Drive as follows. Since Github cannot store repositories larger than 1GB in size, we must manually save the datasets. Create a new folder called `data`in the Google Drive folder. We now import three different datasets into this folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brkqk6Z0NyeM",
        "colab_type": "text"
      },
      "source": [
        "First dataset is from https://github.com/ieee8023/covid-chestxray-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp1NQ0upOpC6",
        "colab_type": "text"
      },
      "source": [
        "Second dataset is from https://github.com/agchung/Figure1-COVID-chestxray-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ210phSOuJR",
        "colab_type": "text"
      },
      "source": [
        "Third dataset is from https://www.kaggle.com/c/rsna-pneumonia-detection-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmMwQgHdOy4G",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Keep in mind we already have these destination files specified in the `config.yml` file located in our Google Drive as `/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/data/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG85RhrsPO14",
        "colab_type": "text"
      },
      "source": [
        "# Executing the Code\n",
        "Now that we have our dataset in our Google Drive, we can start executing the code. In order to carry out the preprocessing code to create Pandas DataFrames of filenames and labels, run the following command. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7xa24oXMlw4",
        "colab_type": "code",
        "outputId": "22c171cc-6960-4ef8-a75c-4fd3274d7182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/data/\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7vB-08BWWum",
        "colab_type": "code",
        "outputId": "a6308bea-4a13-480d-a8e1-a5e572c705b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.yml  __init__.py  preprocess.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK2ge1vISGBp",
        "colab_type": "code",
        "outputId": "38ad1ea4-80b4-42a1-d5b8-1b5a99874292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!python \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/data/preprocess.py\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/data/preprocess.py\", line 168, in <module>\n",
            "    preprocess()\n",
            "  File \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/data/preprocess.py\", line 149, in preprocess\n",
            "    file_df = build_dataset(cfg)\n",
            "  File \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/data/preprocess.py\", line 57, in build_dataset\n",
            "    ds = dicom.dcmread(os.path.join(rsna_data_path + 'stage_2_train_images/' + filename + '.dcm'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pydicom/filereader.py\", line 846, in dcmread\n",
            "    fp = open(fp, 'rb')\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/data/rsna/stage_2_train_images/0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WxwFXuQXlQH",
        "colab_type": "text"
      },
      "source": [
        "If you have correctly saved the datasets in the `data` folder, the preprocessing python file will save the preprocessed DataFrames and corresponding images of the dataset within the `data/preprocessed/` folder. We can now observe that we have new folders titled `train, test,` and `val` within `data/preprocessed`, and three new files titled `train_set.csv, val_set.csv, and test_set.csv.`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyjT4MvUZh50",
        "colab_type": "text"
      },
      "source": [
        "Now that we have preprocessed the files, we can now train the neural network by running `train.py`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijP3LOK1ZwYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/train.py\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDLwQ9z9Z3Qb",
        "colab_type": "text"
      },
      "source": [
        "Please take note that training the neural networks may take several hours using GPU on Colab. The K80 GPU on Colab may be very slow so please be patient. Ensure that Colab does not timeout during code execution. We follow a few optimizations to make the processing more efficient such as **lowering the epochs significantly from the default 200 to 10**. We also have updated config.yml to use our Google Drive project destination after the model weights are generated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QTCOtYb32m_",
        "colab_type": "text"
      },
      "source": [
        "In this project, we carry out binary prediction; we only predict 0 or 1 in case the predictor predicts a case of COVID-19. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo4qN4Od4ZZU",
        "colab_type": "text"
      },
      "source": [
        "#LIME Explanations\n",
        "Because we use a neural network as our model, it is not easy to describe the rules or heuristics that it uses. Therefore we use Local Interpretable Model-Agnostic Explanations (LIME) to describe the outputs of the neural network, which conducts informed feature engineering based on any obviously inconsequential features. To generate explanations for our test images, run the following command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sid9mLqz5031",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4e74a209-e083-4671-b62f-5c2c0245975b"
      },
      "source": [
        "!python \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/interpretability/lime_explain.py\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/My Drive/COVID(ds5786)/Explainable-COVID-19-Pneumonia/covid_19/src/interpretability/lime_explain.py\", line 11, in <module>\n",
            "    from src.visualization.visualize import visualize_explanation\n",
            "ModuleNotFoundError: No module named 'src'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9VC3WBT52N2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "After running this code for 2-3 test cases, an image will be generated that depicts the superpixels contributed most to the model's prediction. These superpixels that contributed toward a prediction of COVID-19 are colored green and superpixels that contributed against a prediction of COVID-19 are colored red. In the same folder, we have a CSV containing the prediction results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Uw3-8M8YOV",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/dnezan/Explainable-COVID-19-Pneumonia/master/covid_19/results/predictions/LIME_example0.png)"
      ]
    }
  ]
}